{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed4ae4b-ef92-445c-9a04-81ac3ed99ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3def0e93-9aab-4f26-bf36-8e347a809ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from copy import deepcopy\n",
    "import missingno as msno\n",
    "import time\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from joblib import Parallel, delayed\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy import stats\n",
    "from scipy.stats import kruskal\n",
    "from tqdm import tqdm\n",
    "\n",
    "from LRE import LogisticRegressionEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a63072-c54c-42e9-96cb-abe2be30bad4",
   "metadata": {},
   "source": [
    "# The necessary EDA steps that has to be done for the logistic regression ensemble is the following:\n",
    "\n",
    "- Handle missing values\n",
    "- Feature Scaling of continuous features\n",
    "- One hot encode the categorical features\n",
    "- Encode the target features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac819eb-5702-4a7f-94d9-6a845da5cc1a",
   "metadata": {},
   "source": [
    "# Ionosphere dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32fd30b6-d0eb-4ba7-b729-60a6457bfc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>-0.20275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>0.89391</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>0.96510</td>\n",
       "      <td>0.03281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>0.94124</td>\n",
       "      <td>0.01766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.89724</td>\n",
       "      <td>-0.03315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>0.78735</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1        2        3        4        5        6        7        8  \\\n",
       "1 0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000  0.03760   \n",
       "  0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000 -0.04549   \n",
       "  0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965  0.01198   \n",
       "  0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000  0.00000   \n",
       "  0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152 -0.16399   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "  0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441 -0.04622   \n",
       "  0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590  0.01606   \n",
       "  0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584  0.02446   \n",
       "  0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746  0.00110   \n",
       "  0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928 -0.09139   \n",
       "\n",
       "           9       10  ...       24       25       26       27       28  \\\n",
       "1 0  0.85243 -0.17755  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090   \n",
       "  0  0.50874 -0.67743  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593   \n",
       "  0  0.73082  0.05346  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365   \n",
       "  0  0.00000  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099   \n",
       "  0  0.52798 -0.20275  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "  0  0.89391  0.13130  ... -0.04202  0.83479  0.00123  1.00000  0.12815   \n",
       "  0  0.96510  0.03281  ...  0.01361  0.93522  0.04925  0.93159  0.08168   \n",
       "  0  0.94124  0.01766  ...  0.03193  0.92489  0.02542  0.92120  0.02242   \n",
       "  0  0.89724 -0.03315  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238   \n",
       "  0  0.78735  0.06678  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703   \n",
       "\n",
       "          29       30       31       32  target  \n",
       "1 0  0.42267 -0.54487  0.18641 -0.45300       g  \n",
       "  0 -0.16626 -0.06288 -0.13738 -0.02447       b  \n",
       "  0  0.60436 -0.24180  0.56045 -0.38238       g  \n",
       "  0  0.25682  1.00000 -0.32382  1.00000       b  \n",
       "  0 -0.05707 -0.59573 -0.04608 -0.65697       g  \n",
       "..       ...      ...      ...      ...     ...  \n",
       "  0  0.86660 -0.10714  0.90546 -0.04307       g  \n",
       "  0  0.94066 -0.00035  0.91483  0.04712       g  \n",
       "  0  0.92459  0.00442  0.92697 -0.00577       g  \n",
       "  0  0.96022 -0.03757  0.87403 -0.16243       g  \n",
       "  0  0.75747 -0.06678  0.85764 -0.06151       g  \n",
       "\n",
       "[351 rows x 33 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [i for i in range(1,34)]\n",
    "feature_names[-1] = \"target\"\n",
    "ion_df = pd.read_csv(\"data/ionosphere/ionosphere.data\", header=None, names=feature_names)\n",
    "ion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79f80b6d-6fc9-417a-9419-c85022b732f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ion_df.drop(\"target\", axis=1)\n",
    "y = ion_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6e994e9-60e2-4555-9f58-90315d0fa293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>0.028250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1           2           3           4           5           6   \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.641342    0.044372    0.601068    0.115889    0.550095    0.119360   \n",
       "std      0.497708    0.441435    0.519862    0.460810    0.492654    0.520750   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      0.472135   -0.064735    0.412660   -0.024795    0.211310   -0.054840   \n",
       "50%      0.871110    0.016310    0.809200    0.022800    0.728730    0.014710   \n",
       "75%      1.000000    0.194185    1.000000    0.334655    0.969240    0.445675   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               7           8           9           10  ...          23  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.511848    0.181345    0.476183    0.155040  ...    0.396135   \n",
       "std      0.507066    0.483851    0.563496    0.494817  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%      0.087110   -0.048075    0.021120   -0.065265  ...    0.000000   \n",
       "50%      0.684210    0.018290    0.667980    0.028250  ...    0.553890   \n",
       "75%      0.953240    0.534195    0.957895    0.482375  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "               24          25          26          27          28          29  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               30          31          32  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm = 2 * ((X - X.min()) / (X.max() - X.min())) - 1\n",
    "X_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aa56bd2-5a2b-4f03-93da-148b8ffab916",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = [0 if u == 'b' else 1 for u in y]\n",
    "y_encoded = np.asarray(y_encoded)\n",
    "X_final = np.asarray(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e76412-11c6-4873-afbd-92e3bd689266",
   "metadata": {},
   "source": [
    "### Start by using Bayesian optimisation to tune the learning rate, epochs and patience parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2aa2768-cc36-4fef-aa38-b37201b9b558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.024526126311336792, 6320, 9]\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1.4507\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.006173770394704579, 13929, 5]\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 1.2312\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.0023864188780056083, 10678, 6]\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.9663\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.008967376801947965, 2636, 9]\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.2701\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.06541210527692738, 1023, 10]\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.1141\n",
      "Function value obtained: 0.0685\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.007119418600172993, 18738, 5]\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 1.5695\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.00011727009450102244, 16218, 7]\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 2.3984\n",
      "Function value obtained: 0.0661\n",
      "Current minimum: 0.0655\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.000138037469635328, 29239, 6]\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 3.7385\n",
      "Function value obtained: 0.0644\n",
      "Current minimum: 0.0644\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.00018699039697141505, 18933, 7]\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 2.6396\n",
      "Function value obtained: 0.0644\n",
      "Current minimum: 0.0644\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0890620438616169, 14536, 9]\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 0.0162\n",
      "Function value obtained: 0.0701\n",
      "Current minimum: 0.0644\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.010988100318524612, 14064, 5]\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 1.2239\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0644\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.0670818864334629, 17335, 7]\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 1.4087\n",
      "Function value obtained: 0.0709\n",
      "Current minimum: 0.0644\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.00011166029133981341, 7696, 6]\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 1.3929\n",
      "Function value obtained: 0.0622\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.011214774784159465, 18690, 9]\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 1.8121\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.0003312027701465944, 12341, 6]\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 1.4733\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.01845373292661596, 13330, 6]\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 1.0730\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.005047786565710609, 1908, 9]\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 0.2047\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.0022349221517675515, 12459, 10]\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 1.0865\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.015199034037054089, 10470, 8]\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 0.8670\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.0036517646487517594, 28874, 9]\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 2.6278\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.005293734388912058, 7257, 6]\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.7965\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.00067711276885365, 8124, 7]\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.1497\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.00012045423858713819, 3973, 6]\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.9021\n",
      "Function value obtained: 0.0672\n",
      "Current minimum: 0.0622\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.00011850345598328692, 9809, 6]\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0016\n",
      "Function value obtained: 0.0621\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.0006645001078988072, 24211, 6]\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.6729\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[0.0001971641167878604, 24066, 7]\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.2554\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[0.0011438063476332202, 9371, 6]\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.1211\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[0.09766376279068852, 17032, 5]\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1875\n",
      "Function value obtained: 0.0734\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[0.0489882318923552, 29679, 10]\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.6670\n",
      "Function value obtained: 0.0649\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[0.000584674814648627, 19527, 10]\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1409\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "[0.0014416257338062137, 5583, 8]\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.9478\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "[0.05836788360972345, 27996, 10]\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.3922\n",
      "Function value obtained: 0.0679\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "[0.00015066977848158874, 21901, 8]\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.5855\n",
      "Function value obtained: 0.0644\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "[0.011407499465845112, 21316, 8]\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1013\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "[0.08755630309407408, 22493, 7]\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.1407\n",
      "Function value obtained: 0.0725\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "[0.0027746885713732343, 20570, 8]\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.2386\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "[0.05134075728334334, 25882, 6]\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.5754\n",
      "Function value obtained: 0.0649\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "[0.09327503014343008, 26501, 5]\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2353\n",
      "Function value obtained: 0.0734\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "[0.0003975528335757526, 25317, 5]\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.0520\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "[0.001358462999782649, 15558, 10]\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.9396\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "[0.007411556811279708, 4810, 6]\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.7168\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "[0.027026556490607007, 11534, 8]\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.3170\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "[0.003905892317772805, 18082, 7]\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.9703\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "[0.00021205415366015514, 3282, 6]\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8073\n",
      "Function value obtained: 0.0644\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "[0.00010299354572862549, 23396, 7]\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.8048\n",
      "Function value obtained: 0.0661\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "[0.011799383304112575, 8748, 7]\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.2667\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "[0.027425575562132733, 26671, 7]\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.4990\n",
      "Function value obtained: 0.0666\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "[0.00010434755549216374, 20236, 6]\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.4222\n",
      "Function value obtained: 0.0661\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "[0.007169782960282129, 29697, 9]\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.8933\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0621\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "[0.009536921504458526, 29971, 10]\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.3321\n",
      "Function value obtained: 0.0655\n",
      "Current minimum: 0.0621\n",
      "Best hyperparameters found:\n",
      "Learning rate (eta): 0.00011850345598328692\n",
      "Number of epochs units: 9809\n",
      "Patience: 6\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_single_fold(model_params, X, y, train_indices, val_indices, test_indices, fold_num):\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    # Unpack model parameters\n",
    "    eta, num_epochs, patience = model_params\n",
    "\n",
    "    # Initialize the model with the current set of hyperparameters\n",
    "    model = LogisticRegressionEnsemble(num_models=1, learning_rate=eta, iterations=num_epochs, patience=patience, num_features=1)\n",
    "\n",
    "    model.random_state = fold_num\n",
    "    weights, loss = model.fit_single_model(model.apply_polynomial_features(X_train), y_train, X_val=model.apply_polynomial_features(X_val), y_val=y_val, curr_iteration=fold_num)\n",
    "    y_pred = np.asarray([0 if u < 0.5 else 1 for u in model.sigmoid(model.apply_polynomial_features(X_test) @ weights)])\n",
    "    score = model.f1_score(y_test, y_pred)\n",
    "    return 1-score\n",
    "\n",
    "def cross_validate_parallel(model_params, X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    folds = list(kf.split(X))\n",
    "\n",
    "    def get_indices(i):\n",
    "        test_indices = folds[i][1]\n",
    "        val_indices = folds[i-1][1]\n",
    "        train_indices = np.concatenate([folds[j][1] for j in range(len(folds)) if j not in [i, i-1]])\n",
    "        return train_indices, val_indices, test_indices\n",
    "\n",
    "    scores = Parallel(n_jobs=5)(\n",
    "        delayed(cross_validate_single_fold)(\n",
    "            model_params, X, y, *get_indices(i), i\n",
    "        ) for i in range(n_splits)\n",
    "    )\n",
    "\n",
    "    scores_acc = np.mean(scores)\n",
    "    scores_std = np.std(scores)\n",
    "    return (scores_acc + scores_std) / 2\n",
    "\n",
    "def objective(params):\n",
    "    print(params)\n",
    "    return cross_validate_parallel(params, X_final, y_encoded)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "search_space = [\n",
    "    Real(1e-4, 1e-1, \"log-uniform\", name='eta'),\n",
    "    Integer(1000, 30000, name='num_epochs'),\n",
    "    Integer(5, 10, name='patience'),\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(\n",
    "    objective,\n",
    "    search_space,\n",
    "    n_calls=50,\n",
    "    n_initial_points=20,\n",
    "    random_state=42,\n",
    "    noise=1e-8,\n",
    "    n_jobs = 1,\n",
    "    acq_func='EI',  # Expected Improvement acquisition function\n",
    "    acq_optimizer='auto',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(f\"Learning rate (eta): {result.x[0]}\")\n",
    "print(f\"Number of epochs units: {result.x[1]}\")\n",
    "print(f\"Patience: {result.x[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee909da-c4a6-424f-8e22-ecfe9285f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "bag_size_values = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "num_features_values = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "num_models_values = [5, 10, 20, 50, 100]\n",
    "\n",
    "# Initialize a DataFrame to store results\n",
    "results = pd.DataFrame(columns=[\"bag_size\", \"num_features\", \"num_models\", \"fold\", \"f1_score\"])\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over each parameter combination\n",
    "for bag_size in tqdm(bag_size_values):\n",
    "    for num_features in num_features_values:\n",
    "        for num_models in num_models_values:\n",
    "            f1_scores = []\n",
    "\n",
    "            # Perform cross-validation\n",
    "            for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "                X_train, X_test = X_final[train_index], X_final[test_index]\n",
    "                y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "                \n",
    "                # Create and fit the ensemble model\n",
    "                model = LogisticRegressionEnsemble(\n",
    "                    num_models=num_models, bag_size=bag_size, num_features=num_features, n_jobs=6, learning_rate=0.00011850345598328692,\n",
    "                    patience=6, iterations=9809, random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict and evaluate F1 score\n",
    "                y_pred = model.predict(X_test)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                \n",
    "                # Append results for each fold\n",
    "                results = pd.concat([results, pd.DataFrame([{\n",
    "                        \"bag_size\": bag_size,\n",
    "                        \"num_features\": num_features,\n",
    "                        \"num_models\": num_models,\n",
    "                        \"fold\": fold + 1,\n",
    "                        \"f1_score\": f1\n",
    "                    }])], ignore_index=True)\n",
    "\n",
    "# Save the results DataFrame to a JSON file\n",
    "results.to_csv(\"results/ionosphere_linear_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9f43c-c835-41eb-965e-0995c1a8be7c",
   "metadata": {},
   "source": [
    "## Non linear logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1834f046-a8b1-438e-ae88-f89bd8761138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.024526126311336792, 6320, 9, 0.6, 2]\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1.9713\n",
      "Function value obtained: 0.0467\n",
      "Current minimum: 0.0467\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.00019949166150633933, 14318, 7, 0.4, 3]\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 41.5045\n",
      "Function value obtained: 0.0431\n",
      "Current minimum: 0.0431\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.00014765043713594345, 21938, 10, 0.4, 3]\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 52.9077\n",
      "Function value obtained: 0.0431\n",
      "Current minimum: 0.0431\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.007119418600172993, 18738, 5, 0.4, 3]\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 14.2774\n",
      "Function value obtained: 0.0433\n",
      "Current minimum: 0.0431\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.0015833718339012064, 2353, 10, 0.5, 2]\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.9014\n",
      "Function value obtained: 0.0474\n",
      "Current minimum: 0.0431\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.007164040428191017, 12091, 10, 0.6, 3]\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 14.3885\n",
      "Function value obtained: 0.0498\n",
      "Current minimum: 0.0431\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.010988100318524612, 14064, 5, 0.8, 3]\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 5.2594\n",
      "Function value obtained: 0.0502\n",
      "Current minimum: 0.0431\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.00143301094556357, 1463, 6, 0.5, 3]\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 4.1740\n",
      "Function value obtained: 0.0421\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.0067606736669594564, 25163, 6, 0.5, 2]\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 5.9472\n",
      "Function value obtained: 0.0541\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.01845373292661596, 13330, 6, 0.6, 2]\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 3.6914\n",
      "Function value obtained: 0.0443\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.03363987115958797, 14043, 7, 0.8, 3]\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 1.0674\n",
      "Function value obtained: 0.0554\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.0009541624171184559, 17543, 8, 0.8, 3]\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 37.6632\n",
      "Function value obtained: 0.0513\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.017456626922659323, 16651, 8, 0.8, 3]\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 3.6309\n",
      "Function value obtained: 0.0474\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.0006729728537157745, 9592, 6, 0.4, 2]\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 2.1421\n",
      "Function value obtained: 0.0451\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.0015298348658397908, 9511, 5, 0.4, 3]\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 9.1037\n",
      "Function value obtained: 0.0423\n",
      "Current minimum: 0.0421\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.02347073130303155, 18573, 10, 0.7, 3]\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 1.1945\n",
      "Function value obtained: 0.0390\n",
      "Current minimum: 0.0390\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.03549079546095974, 14034, 5, 0.5, 3]\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 1.5692\n",
      "Function value obtained: 0.0487\n",
      "Current minimum: 0.0390\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.00994871683276103, 18148, 6, 0.6, 2]\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 4.6908\n",
      "Function value obtained: 0.0425\n",
      "Current minimum: 0.0390\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.08225007188121396, 25619, 9, 0.5, 2]\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 0.0643\n",
      "Function value obtained: 0.0496\n",
      "Current minimum: 0.0390\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.000132221100824003, 21609, 6, 0.6, 2]\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 8.6959\n",
      "Function value obtained: 0.0406\n",
      "Current minimum: 0.0390\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.056836064555955766, 18033, 9, 0.7, 3]\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4943\n",
      "Function value obtained: 0.0691\n",
      "Current minimum: 0.0390\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.00010199699620384331, 2797, 10, 0.7, 3]\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 12.6814\n",
      "Function value obtained: 0.0369\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.001973148632685339, 1729, 6, 0.6, 3]\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.5842\n",
      "Function value obtained: 0.0475\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.00010291585878945613, 3572, 10, 0.5, 3]\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.9328\n",
      "Function value obtained: 0.0370\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.001015584168972722, 4095, 6, 0.4, 3]\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6329\n",
      "Function value obtained: 0.0431\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[0.00018913384562776336, 11412, 5, 0.6, 3]\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 36.7213\n",
      "Function value obtained: 0.0458\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[0.00013865410023133952, 14637, 7, 0.5, 2]\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.4008\n",
      "Function value obtained: 0.0475\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[0.00021313833126237997, 15466, 9, 0.4, 2]\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.1888\n",
      "Function value obtained: 0.0435\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[0.03643811454299802, 6307, 5, 0.7, 2]\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3613\n",
      "Function value obtained: 0.0474\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[0.00017288238790998028, 2957, 5, 0.4, 2]\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4579\n",
      "Function value obtained: 0.0468\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "[0.003072116446357139, 28278, 8, 0.8, 2]\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.8814\n",
      "Function value obtained: 0.0458\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "[0.0002043154034425563, 14383, 7, 0.4, 2]\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.5771\n",
      "Function value obtained: 0.0426\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "[0.00011227192736772314, 21581, 10, 0.4, 2]\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9391\n",
      "Function value obtained: 0.0413\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "[0.08950821099468793, 28848, 9, 0.4, 3]\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.6761\n",
      "Function value obtained: 0.0629\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "[0.0015844350646533351, 18429, 10, 0.7, 2]\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.0063\n",
      "Function value obtained: 0.0383\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "[0.01371697817163943, 4994, 10, 0.5, 3]\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.5676\n",
      "Function value obtained: 0.0432\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "[0.00021083199276240134, 1452, 10, 0.7, 2]\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.3378\n",
      "Function value obtained: 0.0383\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "[0.010077705249294291, 16560, 10, 0.7, 2]\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.1193\n",
      "Function value obtained: 0.0384\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "[0.004807262035066666, 4686, 10, 0.7, 3]\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0852\n",
      "Function value obtained: 0.0434\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "[0.0034907817805120466, 19099, 10, 0.4, 2]\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.1123\n",
      "Function value obtained: 0.0439\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "[0.021899935893897726, 16665, 7, 0.4, 2]\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.8622\n",
      "Function value obtained: 0.0509\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "[0.014402459414123754, 14263, 10, 0.7, 3]\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.4406\n",
      "Function value obtained: 0.0434\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "[0.0013030688007776056, 30000, 5, 0.7, 3]\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 43.7602\n",
      "Function value obtained: 0.0448\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "[0.0005877183315051808, 28939, 10, 0.7, 2]\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.8023\n",
      "Function value obtained: 0.0376\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "[0.0678273767542126, 24538, 10, 0.5, 2]\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3196\n",
      "Function value obtained: 0.0528\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "[0.040147208953644396, 27211, 10, 0.7, 2]\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3504\n",
      "Function value obtained: 0.0464\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "[0.03816978893301268, 30000, 10, 0.7, 2]\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3327\n",
      "Function value obtained: 0.0476\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "[0.00013284909346659526, 23837, 10, 0.8, 2]\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 15.1865\n",
      "Function value obtained: 0.0383\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "[0.00014362680963656875, 22105, 10, 0.5, 2]\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.8217\n",
      "Function value obtained: 0.0474\n",
      "Current minimum: 0.0369\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "[0.04943008813422035, 22212, 10, 0.8, 3]\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0062\n",
      "Function value obtained: 0.0660\n",
      "Current minimum: 0.0369\n",
      "Best hyperparameters found:\n",
      "Learning rate (eta): 0.00010199699620384331\n",
      "Number of epochs units: 2797\n",
      "Patience: 10\n",
      "Number of nonlinear features: 0.7\n",
      "Polynomial degree: 3\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_single_fold(model_params, X, y, train_indices, val_indices, test_indices, fold_num):\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    # Unpack model parameters\n",
    "    eta, num_epochs, patience, num_nonlinear_features, polynomial_degree = model_params\n",
    "\n",
    "    # Initialize the model with the current set of hyperparameters\n",
    "    model = LogisticRegressionEnsemble(num_models=1, learning_rate=eta, iterations=num_epochs, patience=patience, polynomial_degree=polynomial_degree,\n",
    "                                       num_features=1, num_nonlinear_features=num_nonlinear_features)\n",
    "\n",
    "    model.random_state = fold_num\n",
    "\n",
    "    X_transform = model.apply_polynomial_features(X_train)\n",
    "    nonlinear_feature_idx = model.select_random_features(X_transform, fold_num)\n",
    "    \n",
    "    weights, loss = model.fit_single_model(X_transform[:, nonlinear_feature_idx], y_train, X_val=model.apply_polynomial_features(X_val)[:, nonlinear_feature_idx], y_val=y_val, curr_iteration=fold_num)\n",
    "    y_pred = np.asarray([0 if u < 0.5 else 1 for u in model.sigmoid(model.apply_polynomial_features(X_test)[:,nonlinear_feature_idx] @ weights)])\n",
    "    score = model.f1_score(y_test, y_pred)\n",
    "    return 1-score\n",
    "\n",
    "def cross_validate_parallel(model_params, X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    folds = list(kf.split(X))\n",
    "\n",
    "    def get_indices(i):\n",
    "        test_indices = folds[i][1]\n",
    "        val_indices = folds[i-1][1]\n",
    "        train_indices = np.concatenate([folds[j][1] for j in range(len(folds)) if j not in [i, i-1]])\n",
    "        return train_indices, val_indices, test_indices\n",
    "\n",
    "    scores = Parallel(n_jobs=5)(\n",
    "        delayed(cross_validate_single_fold)(\n",
    "            model_params, X, y, *get_indices(i), i\n",
    "        ) for i in range(n_splits)\n",
    "    )\n",
    "\n",
    "    scores_acc = np.mean(scores)\n",
    "    scores_std = np.std(scores)\n",
    "    return (scores_acc + scores_std) / 2\n",
    "\n",
    "def objective(params):\n",
    "    print(params)\n",
    "    return cross_validate_parallel(params, X_final, y_encoded)\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "search_space = [\n",
    "    Real(1e-4, 1e-1, \"log-uniform\", name='eta'),\n",
    "    Integer(1000, 30000, name='num_epochs'),\n",
    "    Integer(5, 10, name='patience'),\n",
    "    Categorical([0.4, 0.5, 0.6, 0.7, 0.8], name='num_nonlinear_features'),\n",
    "    Integer(2,3, name='polynomial_degree')\n",
    "]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "result = gp_minimize(\n",
    "    objective,\n",
    "    search_space,\n",
    "    n_calls=50,\n",
    "    n_initial_points=20,\n",
    "    random_state=42,\n",
    "    noise=1e-8,\n",
    "    n_jobs = 1,\n",
    "    acq_func='EI',  # Expected Improvement acquisition function\n",
    "    acq_optimizer='auto',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(f\"Learning rate (eta): {result.x[0]}\")\n",
    "print(f\"Number of epochs units: {result.x[1]}\")\n",
    "print(f\"Patience: {result.x[2]}\")\n",
    "print(f\"Number of nonlinear features: {result.x[3]}\")\n",
    "print(f\"Polynomial degree: {result.x[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70fd77c-0add-4287-9f63-3d06051c63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "bag_size_values = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "num_features_values = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "num_models_values = [5, 10, 20, 50, 100]\n",
    "# Initialize a DataFrame to store results\n",
    "nl_results = pd.DataFrame(columns=[\"bag_size\", \"num_features\", \"num_models\", \"fold\", \"f1_score\"])\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over each parameter combination\n",
    "for bag_size in tqdm(bag_size_values):\n",
    "    for num_features in num_features_values:\n",
    "        for num_models in num_models_values:\n",
    "            f1_scores = []\n",
    "\n",
    "            # Perform cross-validation\n",
    "            for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "                X_train, X_test = X_final[train_index], X_final[test_index]\n",
    "                y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "                \n",
    "                # Create and fit the ensemble model\n",
    "                model = LogisticRegressionEnsemble(\n",
    "                    num_models=num_models,\n",
    "                    bag_size=bag_size,\n",
    "                    num_features=num_features,\n",
    "                    n_jobs=6,\n",
    "                    learning_rate=0.00010199699620384331,\n",
    "                    patience=10,\n",
    "                    polynomial_degree=3,\n",
    "                    num_nonlinear_features=0.7,\n",
    "                    iterations=2797,\n",
    "                    random_state=42\n",
    "                )\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict and evaluate F1 score\n",
    "                y_pred = model.predict(X_test)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                \n",
    "                # Append results for each fold\n",
    "                nl_results = pd.concat([nl_results, pd.DataFrame([{\n",
    "                        \"bag_size\": bag_size,\n",
    "                        \"num_features\": num_features,\n",
    "                        \"num_models\": num_models,\n",
    "                        \"fold\": fold + 1,\n",
    "                        \"f1_score\": f1\n",
    "                    }])], ignore_index=True)\n",
    "# Save the results DataFrame to a JSON file\n",
    "nl_results.to_csv(\"results/ionosphere_nonlinear_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
